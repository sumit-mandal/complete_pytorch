{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "765e9e41-19d9-421d-a30c-98736146aad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data \n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ae8e9cf-e3dd-4af1-8136-b72bf96e5125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_movie_conv = 'archive/movie_conversations.txt'\n",
    "corpus_movie_lines = 'archive/movie_lines.txt'\n",
    "max_len = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6f2b641-07e8-4f3c-8d36-38a94b4ef42c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(corpus_movie_conv,'r') as c:\n",
    "    conv = c.readlines()\n",
    "    \n",
    "with open(corpus_movie_lines,'r', encoding='iso-8859-1') as l:\n",
    "    lines = l.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fefc38c6-423d-44e0-8401-d6ad2318b82c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines_dict = {}\n",
    "\n",
    "for line in lines:\n",
    "    objects = line.split(\" +++$+++ \")\n",
    "    \n",
    "    lines_dict[objects[0]] = objects[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea3dc520-3496-4382-9d77-bf4450da2ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punc(string):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*'''\n",
    "    no_punc = \" \"\n",
    "    \n",
    "    for char in string:\n",
    "        if char not in punctuations:\n",
    "            no_punc = no_punc + char\n",
    "            \n",
    "    return no_punc.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732a909-e12e-462b-bc9a-117035c6cf30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67152879-86aa-42ec-9130-57ac9e677de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for con in conv:\n",
    "    ids = eval(con.split(\" +++$+++ \")[-1])\n",
    "    for i in range(len(ids)):\n",
    "        qa_pairs = []\n",
    "        \n",
    "        if i==len(ids)-1:\n",
    "            break\n",
    "        \n",
    "        first = remove_punc(lines_dict[ids[i]].strip())      \n",
    "        second = remove_punc(lines_dict[ids[i+1]].strip())\n",
    "        qa_pairs.append(first.split()[:max_len])\n",
    "        qa_pairs.append(second.split()[:max_len])\n",
    "        pairs.append(qa_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc0909c-c079-42d8-b4e9-3b8a4fb895cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Remove words that occurs less than 5 times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00e59955-bb84-45c0-932f-4850eb108aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_freq = Counter()\n",
    "\n",
    "for pair in pairs:\n",
    "    word_freq.update(pair[0])\n",
    "    word_freq.update(pair[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59455b6d-2a8e-44a0-aa6b-30ab782a1666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "733b0bf9-63bc-46f2-ad00-cacba5187244",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_word_freq = 5\n",
    "words = []\n",
    "for w in word_freq.keys():\n",
    "    if word_freq[w] > min_word_freq:\n",
    "        words.append(w)\n",
    "    \n",
    "word_map = {}\n",
    "for v,k in enumerate(words):\n",
    "    word_map[k] = v+1\n",
    "word_map['<unk>'] = len(word_map) + 1\n",
    "word_map['<start>'] = len(word_map) + 1\n",
    "word_map['<end>'] = len(word_map) + 1\n",
    "word_map['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4af1d9b8-311b-4b99-8f2b-b7017bfd3471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('WORDMAP_corpus.json','w') as j:\n",
    "    json.dump(word_map,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a63e3df7-9c67-4c7b-b695-3169e605d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_question(words,word_map):\n",
    "    \n",
    "    enc_c = [word_map.get(word,word_map['<unk>']) for word in words] + [word_map['<pad>']] * (max_len - len(words))\n",
    "    return enc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca0cf274-0e03-4c7d-8b8a-094a483d4bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_reply(words,word_map):\n",
    "    enc_c = [word_map['<start>']] + [word_map.get(word,word_map['<unk>']) for word in words] + [word_map['<end>']] + [word_map['<pad>']] * (max_len - len(words))\n",
    "    return enc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "731a4215-710e-420b-9e24-a25b7d6dca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "# encode_question(pairs[0][0],word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "364a9332-a040-4708-8aaf-596c5b8616e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs_encoded = []\n",
    "\n",
    "for pair in pairs:\n",
    "    ques = encode_question(pair[0],word_map)\n",
    "    ans = encode_reply(pair[1],word_map)\n",
    "    \n",
    "    pairs_encoded.append([ques,ans])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e1270982-fc38-40be-b79e-3d18db612ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('pairs_encoded.json','w') as w:\n",
    "    json.dump(pairs_encoded,w)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0789086-8d23-4474-a0bf-811aeaa15f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pairs = json.load(open('pairs_encoded.json'))\n",
    "        self.dataset_size = len(self.pairs)\n",
    "        \n",
    "    def __getitem__(self,i):\n",
    "        # Return 1 pair of question and reply\n",
    "        question = torch.LongTensor(self.pairs[i][0])\n",
    "        reply = torch.LongTensor(self.pairs[i][1])\n",
    "        \n",
    "        return question , reply\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95d57d53-9c1d-40c1-8868-04736914f902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 25])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(Dataset(),\n",
    "                                          batch_size = 100,\n",
    "                                          shuffle = True,\n",
    "                                          pin_memory = True)\n",
    "\n",
    "question,reply = next(iter(train_loader))\n",
    "question.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74bace81-872a-413e-af12-9710afb890ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_masks(question,reply_input,reply_target):\n",
    "    def subsequent_mask(size):\n",
    "        mask = torch.triu(torch.ones(size,size)).transpose(0,1).type(dtype=torch.uint8)\n",
    "        return mask.unsequeeze(0)\n",
    "    \n",
    "    question_mask = (question!=0).to(device)\n",
    "    \n",
    "    question_mask = question_mask.unsqueeze(1).unsqueeze(1) # (batch_size ,1 ,1 , max_words)\n",
    "    \n",
    "    \n",
    "    reply_input_mask = reply_input!=0\n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1) # (batch_size,1,max_words)\n",
    "    reply_input_mask = reply_input_mask & subsequent_mask(reply_input.size(-1)).type_as(reply_input_mask.data)\n",
    "    # (batch_size,max_words,max_words)\n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1)\n",
    "    reply_target_mask = reply_target!=0\n",
    "    \n",
    "    return question_mask,reply_input_mask,reply_target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7d3fdf38-d87b-4a88-a511-2116cfd06895",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5\n",
    "mask = torch.triu(torch.ones(size,size)).transpose(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e50dd0-5378-4976-b115-301805e90d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self,vocab_size,d_model, max_len = 50):\n",
    "        super(Embeddings,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.embed = nn.Embedding(vocab_size,d_model)\n",
    "        self.pe = self.create_positinal_encoding(max_len, self.d_model) #positional encoding, call function after creating\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def create_positinal_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "        for pos in range(max_len):   # for each position of the word\n",
    "            for i in range(0, d_model, 2):   # for each dimension of the each position\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)   # include the batch size\n",
    "        return pe\n",
    "        \n",
    "    def forward(self, encoded_words):\n",
    "        embeddings = self.embed(encoded_words) * math.sqrt(self.d_model) # (batch_size, max_words, d_model)\n",
    "        # max_words = embeddings.size(1)\n",
    "        embeddings += self.pe[:,embdeddings.size(1)] # pe will automatically be expanded to the same batch_size as embeddings\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d2d99d2-f015-41f0-91f7-aba18ab7fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,head,d_model):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        assert d_model % heads == 0\n",
    "        self.d_k = d_model // heads\n",
    "        self.heads = heads\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.query = \n",
    "        self.key = \n",
    "        self.value = \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae7f57-f2da-4e42-a7a4-7ac5b9168c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git add .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89502999-3e81-4b7d-85a5-a6c0fd3268df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd30d46-07b7-445c-bdab-d1af83f8e45b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchenv] *",
   "language": "python",
   "name": "conda-env-torchenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
